---
layout: page
title: "광학문자인식(OCR, Optical Character Recognition)"
subtitle: "검정배경 흰색글자 인식"
author:
  - name: "[Tidyverse Korea](https://www.facebook.com/groups/tidyverse/)"
    url: https://www.facebook.com/groups/tidyverse/
    affiliation: Tidyverse Korea
    affiliation_url: https://www.facebook.com/groups/tidyverse/
date: "`r Sys.Date()`"
output:
  html_document: 
    include:
      after_body: footer.html
      before_body: header.html
    toc: yes
    toc_depth: 2
    toc_float: true
    highlight: tango
    code_folding: show
    number_section: true
    self_contained: true
bibliography: bibliography_ingest.bib
csl: biomed-central.csl
urlcolor: blue
linkcolor: blue
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,
                      comment="", digits = 3, tidy = FALSE, prompt = FALSE, fig.align = 'center')

```

<center>
![](fig/ocr-process.png){#id .class width="37%"}
</center>

# OCR 대상 이미지 [^ocr-basics] [^ocr-images] [^ocr-preprocessing] [^ocr-segmentation] {#ocr-image}

[^ocr-images]: [stackoverflow, "tesseract in R - read white font on black background"](https://stackoverflow.com/questions/59750745/tesseract-in-r-read-white-font-on-black-background)

[^ocr-basics]: [Susmith Reddy (Mar 25, 2019), "What is OCR ?", Medium.com](https://medium.com/@susmithreddyvedere/what-is-ocr-7d46dc419eb9)

[^ocr-preprocessing]: [Susmith Reddy (Mar 25, 2019), "Pre-Processing in OCR !!!", Medium.com](https://medium.com/@susmithreddyvedere/what-is-ocr-7d46dc419eb9)

[^ocr-segmentation]: [Susmith Reddy (Mar 26, 2019), Segmentation in OCR !!", Medium.com](https://medium.com/@susmithreddyvedere/what-is-ocr-7d46dc419eb9)


검은색 배경에 흰색글씨가 담긴 이미지에서 텍스트를 추출하는 사례를 살펴보자. 스택오버플로우 ["tesseract in R - read white font on black background"](https://stackoverflow.com/questions/59750745/tesseract-in-r-read-white-font-on-black-background)에 올라온 한장의 이미지를 가지고 시작해보자.

```{r ocr-image}
library(tidyverse)
library(magick)
library(tesseract)

char_image <- image_read("fig/white-character.jpeg")

char_image %>% 
  image_resize("2000x")
```

## 이미지 전처리 {#preprocess-images}

`magick` 객체보다 숫자로 작업하는 것이 경우에 따라서는 더 수월한 경우도 많다.

```{r preprocess-images}

input <- char_image %>% 
  .[[1]] %>% 
  as.numeric() # 숫자가 작업하기 수월하다.

image_read(ifelse(input < .9, 1, 0) ) 
```

## 텍스트 추출 {#extract-ocr-text}

`tessearact` 팩키지 `ocr()` 함수를 사용해서 텍스트를 추출한다.

```{r extract-text-from-image}
ocr_characters <- ifelse(input < .9, 1, 0) %>% 
  image_read() %>% 
  image_resize('500x') %>% # make it smaller to work around the errors
  tesseract::ocr( engine = "eng") %>% 
  str_remove("\n")

ocr_characters
```

## 성능 평가 {#evaluate-ocr-text}

추출된 텍스트와 라벨(정답) 데이터간 문자열 거리(`stringdist`)를 사용하여 거리를 성능지표로 계산해 본다.

```{r evaluate-text-from-image}
library(stringdist)

label <- "TLC200 PRO 2019/10/31 17:33:00"
stringdist(label, ocr_characters)
```

# OCR 성능지표 [^abbyy-accuracy] [@tomaschek2018evaluation] {#ocr-evaluation-metric}

[^abbyy-accuracy]: [ABBYY Technology Portal, "OCR Accuracy Measurement"](https://abbyy.technology/en:kb:tip:ocr-accuracy)

- 글자 단위 정확도 (character metric)
- 단어 단위 정확도 (word metric)

글자 단위 성능지표는 다음과 같이 Precision, Recall을 정의한다.

- $C_\text{precision} = \frac{C_\text{truth}}{C_\text{model}}$
- $C_\text{recall} = \frac{C_\text{model}}{C_\text{truth}}$

단어 단위 성능지표는 `Levenshtein` 거리를 사용하는 것도 좋을 듯 싶다.

OCR 평가 도구는 다음과 같다.

- The ISRI Analytic Tools: [`ocreval`](https://github.com/eddieantonio/ocreval)
- hOCR tools: [`hocr-tools`](https://github.com/tmbdev/hocr-tools)
- An open-source OCR evaluation tool: 자바 [`ocrevalUAtion`](https://github.com/impactcentre/ocrevalUAtion)

# 이미지 이진화 [^image-binarization] {#image-binarization}

OCR (Optical Character Recognition), HTR(Handwritten Text Recognition) 성능향상을 위해서 adaptive thresholding 기법을 적용하는 이미지 이진화(Image Binarization)를 손쉽게 적용할 수 있는 팩키지가 도입되었다. ["image.binarization"](https://github.com/DIGI-VUB/image.binarization) 팩키지는 사실 [Δoxa Binarization Framework](https://github.com/brandonmpetty/Doxa) C/C++ 코드를 R 팩키지로 묶어놓은 것이다. [WebAssembly Demo - Local Adaptive Binarization](https://brandonmpetty.github.io/Doxa/WebAssembly/) 데모가 있으니 살펴보면 좋을 듯 싶다.

[^image-binarization]: [Github, "image.binarization"](https://github.com/DIGI-VUB/image.binarization)

지원되는 알고리즘은 다음과 같다.

- Otsu - "A threshold selection method from gray-level histograms", 1979.
- Bernsen - "Dynamic thresholding of gray-level images", 1986.
- Niblack - "An Introduction to Digital Image Processing", 1986.
- Sauvola - "Adaptive document image binarization", 1999.
- Wolf - "Extraction and Recognition of Artificial Text in Multimedia Documents", 2003.
- Gatos - "Adaptive degraded document image binarization", 2005. (Partial)
- NICK - "Comparison of Niblack inspired Binarization methods for ancient documents", 2009.
- Su - "Binarization of Historical Document Images Using the Local Maximum and Minimum", 2010.
- T.R. Singh - "A New local Adaptive Thresholding Technique in Binarization", 2011.
- Bataineh - "An adaptive local binarization method for document images based on a novel thresholding method and dynamic windows", 2011. (unreproducible)
- ISauvola - "ISauvola: Improved Sauvola’s Algorithm for Document Image Binarization", 2016.
- WAN - "Binarization of Document Image Using Optimum Threshold Modification", 2018.

## 이미지 전처리 {#helloworld-image-binarization}

OTSU 알고리즘으로 텍스트 OCR 작업 수행하기 전에 전처리 작업을 진행한다.

```{r image-binarization-hello-world}
library(magick)
# remotes::install_github("DIGI-VUB/image.binarization")
library(image.binarization)
test_img <- image_read("fig/white-character.jpeg") %>%  image_resize('500x')
converted_img <- image_convert(test_img, format = "PGM", colorspace = "Gray")
processed_img <- image_binarization(converted_img, type = "otsu")

processed_img
```

## 텍스트 추출 {#helloworld-image-binarization-ocr}

`tesseract` 팩키지를 통해 텍스트를 추출하고 정답과 비교해보자.

```{r image-binarization-ocr}
ocred_text <- tesseract::ocr(processed_img, engine = "eng") %>% 
  stringr::str_remove("\n")

ocred_text

stringdist::stringdist(label, ocred_text)
```

## 다양한 방법 {#image-binarization-ocr-automation}

문서에 대해 적절한 방법을 탐색해 본다. 

```{r image-binarization-search-method}
test_img <- image_read("fig/white-character.jpeg") %>%  image_resize('500x')
converted_img <- image_convert(test_img, format = "PGM", colorspace = "Gray")

methods_list <- c("otsu", "sauvola", "wolf")

for(i in seq_along(methods_list)) {
  
  processed_img <- image_binarization(converted_img, type = methods_list[i])
  
  ocred_text <- tesseract::ocr(processed_img, engine = "eng") %>% 
    stringr::str_remove("\n")

  cat(methods_list[i], "- Error :", stringdist::stringdist(label, ocred_text), "\n",
      "Label:", label, "\n",
      "OCRED:", ocred_text, "\n")
}

```
